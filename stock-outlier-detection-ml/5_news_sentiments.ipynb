{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c57fc8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Tesla headlines:\n",
      "['Elon Musk Has a New Plan to Win Back MAGA', 'The End of the Stock Market As We Know It', 'Stephen Miller Owns Stock in Notorious ICE Collaborator Palantir', 'Elon Musk loses $15 billion in net worth after Tesla stock sinks', \"Vox populi, vox dei â€” Elon Musk loves polling people on X. Here's a list of polls he's done, and what happened after.\"]\n",
      "\n",
      "ğŸ§ª Sentiment Example:\n",
      "Elon Musk Has a New Plan to Win Back MAGA\n",
      "{'negative': 0.19564614, 'neutral': 0.010223062, 'positive': 0.79413074}\n",
      "\n",
      "âœ… Sentiment analysis complete.\n"
     ]
    }
   ],
   "source": [
    "# ğŸ—ï¸ Stock News Sentiment Analysis\n",
    "# Phase 2 of Outlier Detection Project\n",
    "# Author: Rehan Chaudhry\n",
    "\n",
    "# =============================\n",
    "# ğŸ“¦ 1. Install dependencies\n",
    "# =============================\n",
    "# Run this cell only once\n",
    "!pip install newsapi-python transformers torch pandas seaborn matplotlib --quiet\n",
    "import pandas as pd\n",
    "\n",
    "# =============================\n",
    "# ğŸ”‘ 2. Load API key for NewsAPI\n",
    "# =============================\n",
    "from newsapi import NewsApiClient\n",
    "\n",
    "NEWS_API_KEY = \"a2b11161eb444bfe96b3b5defccff5cf\"  # ğŸ” Replace with your key\n",
    "newsapi = NewsApiClient(api_key=NEWS_API_KEY)\n",
    "\n",
    "# =============================\n",
    "# ğŸ” 3. Define tickers and search terms\n",
    "# =============================\n",
    "tickers = {\n",
    "    \"TSLA\": \"Tesla\",\n",
    "    \"MSFT\": \"Microsoft\",\n",
    "    \"GOOGL\": \"Google\",\n",
    "    \"AAPL\": \"Apple\",\n",
    "    \"AMZN\": \"Amazon\"\n",
    "}\n",
    "\n",
    "# =============================\n",
    "# ğŸ“° 4. Fetch headlines\n",
    "# =============================\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def fetch_headlines(company_name, days=7):\n",
    "    from_date = (datetime.now() - timedelta(days=days)).strftime(\"%Y-%m-%d\")\n",
    "    headlines = newsapi.get_everything(\n",
    "        q=f\"{company_name} stock\",  # << make sure this is specific\n",
    "        from_param=from_date,\n",
    "        language=\"en\",\n",
    "        sort_by=\"relevancy\",\n",
    "        page_size=50\n",
    "    )\n",
    "    return [article[\"title\"] for article in headlines[\"articles\"]]\n",
    "\n",
    "# Example: Fetch Tesla news\n",
    "tesla_news = fetch_headlines(\"Tesla\", days=30)\n",
    "print(f\"Sample Tesla headlines:\\n{tesla_news[:5]}\")\n",
    "\n",
    "# =============================\n",
    "# ğŸ§  5. Load FinBERT for sentiment\n",
    "# =============================\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.nn.functional import softmax\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")\n",
    "\n",
    "def get_sentiment_score(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    outputs = model(**inputs)\n",
    "    probs = softmax(outputs.logits, dim=1)\n",
    "    labels = [\"negative\", \"neutral\", \"positive\"]\n",
    "    return dict(zip(labels, probs[0].detach().numpy()))\n",
    "\n",
    "# Example: Score 1 headline\n",
    "print(\"\\nğŸ§ª Sentiment Example:\")\n",
    "print(tesla_news[0])\n",
    "print(get_sentiment_score(tesla_news[0]))\n",
    "\n",
    "# =============================\n",
    "# ğŸ“Š 6. Sentiment Summary Table\n",
    "# =============================\n",
    "def analyze_company_sentiment(name):\n",
    "    titles = fetch_headlines(name)\n",
    "    scores = [get_sentiment_score(t) for t in titles]\n",
    "    df = pd.DataFrame(scores)\n",
    "    df['title'] = titles\n",
    "    df['company'] = name\n",
    "    return df\n",
    "\n",
    "all_sentiment = pd.concat([analyze_company_sentiment(name) for name in tickers.values()])\n",
    "all_sentiment.reset_index(drop=True, inplace=True)\n",
    "all_sentiment.to_csv(\"../data/processed/news_sentiment.csv\", index=False)\n",
    "\n",
    "print(\"\\nâœ… Sentiment analysis complete.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
